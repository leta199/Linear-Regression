{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ec2daf",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4316d2",
   "metadata": {},
   "source": [
    "## CHAPTER #1 - HANDLING DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702605c",
   "metadata": {},
   "source": [
    "## Importing dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd27fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages \n",
    "%pip install pandas \n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad17ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f807e9",
   "metadata": {},
   "source": [
    "## Loading data \n",
    "The following datasets provide metrics partitioned by market capitalization, price, volatility, and turnover. The stock market activity metrics are partitioned by decile and the ETP metrics by quartile. \n",
    "\n",
    "I want to look into how cancellation rate is affected by stock volatility.\n",
    "I will loook at decile 1 (the lowest market capitilsation of 10 businesses) and the Market cap decile column as well as its Volatility to see how cancellation rate changes with volatility. \n",
    "I would hypothesise that the greater the volaitilty the greater the rate of cancellation. \n",
    "\n",
    "In our data schema the following are defined:  \n",
    "Market Cap  Decile1- what is the decile_cancel_to_trade (number of cancelled trades/ number of successful trades) for that capitalisation at that date.    \n",
    "Volatility- the amount statsitical variation within in stock decile (e.g decile 1) as that date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ddef7",
   "metadata": {},
   "source": [
    "## Can we predict the the cancelllation rate of a stock based on its volatility?\n",
    "We will use linaer regression to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_path= \"/Users/admin/Desktop/Data Science Career /Python/Python Projects/Linear regression from scratch /decile_quartile_2025_q1/decile_cancel_to_trade_stock.csv\"\n",
    "#Saving path name as variable for read csv argument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_to_cancel_raw=pd.read_csv(decile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32907145",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_to_cancel_raw.head()\n",
    "decile_to_cancel_raw.tail()\n",
    "#A little insight into what our data looks like "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e7b11",
   "metadata": {},
   "source": [
    "## Pre-processing and cleaning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710dc3cb",
   "metadata": {},
   "source": [
    "-For the purposes of this model we will limit our dataset to decile 1.   \n",
    "This is to isloate only volatility and cancellation features for one set of independent and dependent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d77ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_1 = decile_to_cancel_raw[[\"Market Cap Decile1\",\"Volatility Decile1\"]] \n",
    "#extracting features of market cap decile 1\n",
    "#independent variable = volatility decile 1 \n",
    "#dependent varaible = market cap decile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06552522",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(decile_1.rename) #help on how to rename columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_1 = decile_1.round(2)\n",
    "decile_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_1 = decile_1.rename(columns={'Market Cap Decile1':'Cancellation rate','Volatility Decile1':'Volatility'})\n",
    "#renaming columns since we know we are in decile 1 of the canccel to trade file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34507f",
   "metadata": {},
   "source": [
    "## Linear Regression Assumptions\n",
    "In linaer regression we assume a few key aspects of our data:   \n",
    "1) Linearity of the data points. \n",
    "2) Homoscedacity   \n",
    "3) Normality of erros   \n",
    " \n",
    "To test the first asusumptions I will make a basic plot of the two features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7600b3a",
   "metadata": {},
   "source": [
    "### Linearity\n",
    "Plot our indepdent variable vs depedent variable as a scatterplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = decile_1[['Cancellation rate']]\n",
    "y_values = decile_1[['Volatility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86370571",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear = plt.scatter(y_values, x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfc31d",
   "metadata": {},
   "source": [
    "From this plot we can see a few key details, namely: \n",
    "1) Our data has a few outliers.  \n",
    "2) Our data does follow a linear relationship with most values condensed around the centre point of the volatility scale.  \n",
    "3) The linearity is present but does not have a strong gradient meaning the volaitly in decile 1 does not have much predictive power in rehgards to the cencellation rate. I will explore  different features for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86fc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_9 = decile_to_cancel_raw[[\"Market Cap Decile9\",\"Volatility Decile9\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7dad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_2 = decile_9[['Market Cap Decile9']]\n",
    "x_values_2 = decile_9[['Volatility Decile9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29181bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear = plt.scatter(x_values_2, y_values_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f278a",
   "metadata": {},
   "source": [
    "From this plot we can see that:\n",
    "1) There is a string positive linear relationship, therefore volatililty does have predictive power for cancellation rates. \n",
    "2) There is heteroscedacity in the raw data, therefore we may need to apply some kind of transformation to the data but I will make the regression model and then check for homoscedacity in the residuals. \n",
    "3) Interetsing though since this high heteroscedcaity indicates that as stock get more volatile purchasing decisions become more extreme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a18d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_9 = decile_9.rename(columns={'Market Cap Decile9':'Cancellation rate','Volatility Decile9':'Volatility'})\n",
    "#renaming columns since we know we are in decile 9 of the cancel_to_trade file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df986d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box = plt.boxplot(x_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0dac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box = plt.boxplot(y_values_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d585b",
   "metadata": {},
   "source": [
    "From these plots we can see the presence of:\n",
    "1) A significant number of outliers outside the maximum range of the dataset.\n",
    "2) We will use the interquartile range method to impute these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b0454",
   "metadata": {},
   "source": [
    "## OUTLIER REMOVAL \n",
    "I will use the method of removing values above using upper and lower bounds based on quartiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b075e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1- compute Q1 and Q3\n",
    "#Cancellation rates \n",
    "Q1C = decile_9['Cancellation rate'].quantile(0.25)\n",
    "Q3C = decile_9['Cancellation rate'].quantile(0.75)\n",
    "print(Q1C)\n",
    "print(Q3C)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03413096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatiltiy \n",
    "Q1V = decile_9['Volatility'].quantile(0.25)\n",
    "Q3V = decile_9['Volatility'].quantile(0.75)\n",
    "print(Q1V)\n",
    "print(Q3V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Compute IQR\n",
    "#Cancellation rate \n",
    "IQRC = Q3C - Q1C\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715abaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility \n",
    "IQRV= Q3V -Q1V\n",
    "print(IQRV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Find the upper bound and lower bound\n",
    "#Cancellation rate\n",
    "upper_b_Canc = Q3C + 1.5*IQRC\n",
    "print(upper_b_Canc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303113a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility \n",
    "upper_b_Vol = Q3V + 1.5*IQRV\n",
    "print(upper_b_Vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of outliers - https://www.analyticsvidhya.com/blog/2022/09/dealing-with-outliers-using-the-iqr-method/\n",
    "#Cancellation rate\n",
    "decile_9[decile_9['Cancellation rate'] > upper_b_Canc].count()\n",
    "print((70/3329)*100) #percentage of values to impute. Is not excessive ≈ 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility\n",
    "decile_9[decile_9['Volatility'] > upper_b_Vol].count()\n",
    "print((69/3329)*100) #percentage of values to impute. Is not excessive ≈ 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capping outlier values- Since these values represent only upper tail outlers, truncating them would remove information from the data and make our model have \n",
    "#lower predictive power at the high end. Therefore I wil use Winsorization to cap them -https://www.datacamp.com/tutorial/winsorized-mean\n",
    "#Cancellation rate \n",
    "\n",
    "decile_9['Cancellation rate'] = decile_9['Cancellation rate'].clip (upper = upper_b_Canc)\n",
    "decile_9[decile_9['Cancellation rate'] > upper_b_Canc].count() #success \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_9['Volatility'] = decile_9['Volatility'].clip (upper = upper_b_Vol)\n",
    "decile_9[decile_9['Volatility'] > upper_b_Vol].count() #success "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New distribution plots\n",
    "y = decile_9[['Cancellation rate']]\n",
    "x = decile_9[['Volatility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3eaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f46761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ca26e",
   "metadata": {},
   "source": [
    "Now that we have the pre-processed data with linearity and outliers handled we can create our linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020beab",
   "metadata": {},
   "source": [
    "## CHAPTER #2 - LINEAR REGRESSION MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd859b94",
   "metadata": {},
   "source": [
    " ### CLASS CREATION  \n",
    " This class will contain all of the model logic.   \n",
    " The class contains the Linear regression model itself. \n",
    " Each object is a learned model i.e a line for each set of training data   \n",
    "\n",
    " The attributes contain the:  \n",
    " - weight (coefficeint of the independent variable)  \n",
    " - bias (y-intercept) of the line \n",
    "\n",
    " The methods contain all the verbs of the model (functions that change the weight and bias), namely:  \n",
    " - how the model learn weight and bias. \n",
    " - how the model fits the line to the data   \n",
    " - how the line is evaluated e.g R^2 and RMSE. \n",
    " - importsnt data about the model like residuals \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class  LinearRegression(object):\n",
    "    def __init__(self, weight=0, bias=0): #initialises the attributes of the class\n",
    "        self.weight = weight              #stores weight \n",
    "        self.bias = bias                  #stores bias \n",
    "        self.x = []                       #stores our predictor variables (x) as lists  \n",
    "        self.y = []                       #stores our predicted variable (y) as lists \n",
    " \n",
    "    def vectorise(self, x,y):             #defining method to store the data points to be modelled\n",
    "        self.x = x                        #storing the values of x independent variable within the class \n",
    "        self.y = y                        #storing the values of y dependent variable within the class \n",
    "\n",
    "    def predict_y (self):                 #calcualting the predicted y[i] for our optimisation later \n",
    "        y_predict =[]                     #creating an empty list to store all predicted y values \n",
    "        n = len(self.y)\n",
    "\n",
    "        for i in range(n):                #looping over the number of values we have in the dataset \n",
    "            y_predict.append(self.weight*self.x[i] + self.bias)     #calculating predicted y values with line equation and adding predicted values to our list \n",
    "        return y_predict                  \n",
    "\n",
    "#Creating method to get weight\n",
    "    def partial_w(self):                  #partial derivative in regard to weight \n",
    "        y_predict = self.predict_y()\n",
    "        gradient = 0 \n",
    "        n=len(self.y)\n",
    "\n",
    "        for i in range(n):\n",
    "            gradient += self.x[i]*(y_predict[i] - self.y[i])         #partial derivative equation to calculate total partial derivative of weight in regards to error function\n",
    "        return (-2/n)*gradient\n",
    "\n",
    "#Creating method to get bias \n",
    "    def partial_b(self):\n",
    "        y_predict = self.predict_y()\n",
    "        gradient = 0\n",
    "        n=len(self.y)\n",
    "\n",
    "        for i in range(n):\n",
    "            gradient += (y_predict[i]- self.y[i])                     #partial derivative equation to calculate total partial derivative of bias in regards to error function\n",
    "        return (-2/n)*gradient\n",
    "\n",
    "#Numerical optimisation via gradient descent \n",
    "    def optimise(self): \n",
    "        learn_rate = 0.005                 #size of steps we make \"downhill\" to minimise total error in regards to the weight and bias \n",
    "\n",
    "        for i in range(10000):           #number of \"epochs\" we take steps in to minimise aggregate error \n",
    "            self.weight = self.weight + learn_rate * self.partial_w() #optimised weight \n",
    "            self.bias = self.bias + learn_rate * self.partial_b()     #optimised bias \n",
    "            if i % 10 == 0:                #prints out the weight and bias every 10 epochs \n",
    "                print(self.weight, self.bias)\n",
    "    \n",
    "#Residual calculations \n",
    "    def residuals(self):\n",
    "        residuals = []\n",
    "        n=len(self.x)\n",
    "\n",
    "        for i in range(n):\n",
    "            residuals.append(self.y[i] - (self.weight * self.x[i] + self.bias))\n",
    "        return residuals\n",
    "\n",
    "#Evaluation metrics\n",
    "#Mean Square Error  \n",
    "\n",
    "    def mse(self):\n",
    "        mse = 0\n",
    "        mse_list = []\n",
    "        n=len(self.y)\n",
    "        total_error = []\n",
    "\n",
    "        for i in range(n):\n",
    "            total_error.append((self.y[i] - (self.weight * self.x[i] + self.bias))**2)\n",
    "            mse_list.append((1/n)*total_error[i])\n",
    "            mse += mse_list[i]\n",
    "        return mse \n",
    "#R^2\n",
    "    def rsquared(self):\n",
    "        n=len(self.y)\n",
    "        avg_y = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            avg_y += ((1/n)*self.y[i])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240ada1",
   "metadata": {},
   "source": [
    "EXAMPLE WITH SIMPLE LISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "y = [6,7,8,9,10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vectorise(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24baca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46403671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linreg (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
